"""
SignalFlux Dashboard é›†æˆå±‚
å°† Dashboard WebSocket ä¸çœŸå® SignalFlux å·¥ä½œæµè¿æ¥
"""
import asyncio
import threading
from datetime import datetime
from typing import Optional, Callable, Dict, Any, List
from loguru import logger
from queue import Queue

class DashboardCallback:
    """
    Dashboard å›è°ƒç®¡ç†å™¨
    ç”¨äºåœ¨ Agent æ‰§è¡Œè¿‡ç¨‹ä¸­å®æ—¶æ¨é€çŠ¶æ€åˆ° Dashboard
    """
    
    def __init__(self):
        self._event_queue: Queue = Queue()
        self._enabled = False
        self._loop: Optional[asyncio.AbstractEventLoop] = None
        self._broadcast_func: Optional[Callable] = None
    
    def enable(self, broadcast_func: Callable, loop: asyncio.AbstractEventLoop):
        """å¯ç”¨å›è°ƒ"""
        self._enabled = True
        self._broadcast_func = broadcast_func
        self._loop = loop
        logger.info("ğŸ“¡ Dashboard callback enabled")
    
    def disable(self):
        """ç¦ç”¨å›è°ƒ"""
        self._enabled = False
        self._broadcast_func = None
        self._loop = None
    
    def _send_event(self, event_type: str, data: dict):
        """å‘é€äº‹ä»¶åˆ° Dashboard"""
        if not self._enabled or not self._broadcast_func or not self._loop:
            return
        
        try:
            # ä»åŒæ­¥ä»£ç å®‰å…¨åœ°è°ƒç”¨å¼‚æ­¥å‡½æ•°
            asyncio.run_coroutine_threadsafe(
                self._broadcast_func({"type": event_type, "data": data}),
                self._loop
            )
        except Exception as e:
            logger.warning(f"Failed to send dashboard event: {e}")
    
    def phase(self, name: str, progress: int):
        """æ›´æ–°é˜¶æ®µ"""
        self._send_event("progress", {"phase": name, "progress": progress})
    
    def step(self, step_type: str, agent: str, content: str, **kwargs):
        """æ·»åŠ æ­¥éª¤"""
        self._send_event("step", {
            "type": step_type,
            "agent": agent,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            **kwargs
        })
    
    def signal(self, signal_data: dict):
        """æ¨é€ä¿¡å·"""
        self._send_event("signal", signal_data)
    
    def chart(self, ticker: str, data: dict):
        """æ¨é€å›¾è¡¨æ•°æ®"""
        self._send_event("chart", {"ticker": ticker, **data})
    
    def prediction(self, ticker: str, prediction: dict):
        """æ¨é€é¢„æµ‹"""
        self._send_event("prediction", {"ticker": ticker, "prediction": prediction})
    
    def graph(self, graph_data: dict):
        """æ¨é€ä¼ å¯¼å›¾"""
        self._send_event("graph", graph_data)

# å…¨å±€å•ä¾‹
dashboard_callback = DashboardCallback()


class WorkflowRunner:
    """
    å·¥ä½œæµè¿è¡Œå™¨
    åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ SignalFlux å·¥ä½œæµï¼ŒåŒæ—¶é€šè¿‡ DashboardCallback æ¨é€çŠ¶æ€
    """
    
    def __init__(self):
        self._workflow = None
        self._running = False
        self._thread: Optional[threading.Thread] = None
    
    def _ensure_workflow(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å·¥ä½œæµï¼ˆé¿å…å¯¼å…¥æ—¶åŠ è½½æ¨¡å‹ï¼‰"""
        if self._workflow is None:
            from main_flow import SignalFluxWorkflow
            self._workflow = SignalFluxWorkflow(isq_template_id="default_isq_v1")
        return self._workflow
    
    def is_running(self) -> bool:
        return self._running
    
    def run_async(
        self,
        query: Optional[str] = None,
        sources: List[str] = None,
        wide: int = 10,
        run_state: Any = None
    ):
        """åœ¨åå°çº¿ç¨‹å¯åŠ¨å·¥ä½œæµ"""
        if self._running:
            raise RuntimeError("Workflow already running")
        
        self._running = True
        self._thread = threading.Thread(
            target=self._run_workflow,
            args=(query, sources or ["financial"], wide, run_state),
            daemon=True
        )
        self._thread.start()
    
    def _run_workflow(
        self,
        query: Optional[str],
        sources: List[str],
        wide: int,
        run_state: Any
    ):
        """å®é™…æ‰§è¡Œå·¥ä½œæµï¼ˆåœ¨åå°çº¿ç¨‹ä¸­ï¼‰- å®Œæ•´å¤åˆ¶ main_flow.py é€»è¾‘"""
        cb = dashboard_callback
        
        try:
            # ========== Step 0: åˆå§‹åŒ– ==========
            cb.phase("åˆå§‹åŒ–", 5)
            cb.step("system", "System", f"ğŸš€ SignalFlux Workflow å¯åŠ¨")
            cb.step("config", "System", f"Query: {query or 'è‡ªåŠ¨æ‰«æ'}, Sources: {sources}")
            
            workflow = self._ensure_workflow()
            
            # ========== Step 1: Trend Discovery ==========
            cb.phase("çƒ­ç‚¹æ‰«æ", 10)
            cb.step("phase", "System", "ğŸ“¡ --- Step 1: Trend Discovery ---")
            
            # 1.0 æ„å›¾åˆ†æ (å¦‚æœå­˜åœ¨ query) - å…³é”®æ­¥éª¤ï¼
            intent_info = {}
            if query:
                cb.step("thought", "IntentAgent", f"ğŸ§  åˆ†ææŸ¥è¯¢æ„å›¾: {query}")
                try:
                    intent_info = workflow.intent_agent.run(query)
                    if isinstance(intent_info, dict):
                        keywords = intent_info.get("keywords", [])
                        search_queries = intent_info.get("search_queries", [])
                        is_specific = intent_info.get("is_specific_event", False)
                        cb.step("result", "IntentAgent", f"âœ… å…³é”®è¯: {keywords[:3]}, ç‰¹å®šäº‹ä»¶: {is_specific}")
                        cb.step("result", "IntentAgent", f"âœ… æœç´¢è¯: {search_queries[:2]}")
                    else:
                        cb.step("warning", "IntentAgent", "âš ï¸ æ„å›¾åˆ†æè¿”å›éå­—å…¸æ ¼å¼")
                        intent_info = {"search_queries": [query]}
                except Exception as e:
                    cb.step("error", "IntentAgent", f"âŒ æ„å›¾åˆ†æå¤±è´¥: {str(e)[:50]}")
                    intent_info = {"search_queries": [query]}
            
            # 1.1 è§£æ sources
            if "financial" in sources:
                actual_sources = workflow.FINANCIAL_SOURCES.copy()
            elif "all" in sources:
                actual_sources = workflow.ALL_SOURCES.copy()
            else:
                actual_sources = sources
            
            # 1.2 å¤šæºæŠ“å–
            cb.phase("å¤šæºæŠ“å–", 15)
            successful_sources = []
            for source in actual_sources[:5]:  # é™åˆ¶æºæ•°é‡
                cb.step("tool_call", "TrendAgent", f"fetch_hot_news('{source}', count={wide})")
                try:
                    result = workflow.trend_agent.news_toolkit.fetch_hot_news(source, count=wide)
                    if result and len(result) > 0:
                        successful_sources.append(source)
                        cb.step("result", "TrendAgent", f"âœ… {source}: è·å– {len(result)} æ¡")
                    else:
                        cb.step("result", "TrendAgent", f"âš ï¸ {source}: æ— æ•°æ®")
                except Exception as e:
                    cb.step("error", "TrendAgent", f"âŒ {source}: {str(e)[:50]}")
            
            # 1.3 ä¸»åŠ¨æœç´¢ (å…³é”®ï¼æœ‰ query æ—¶æ‰§è¡Œç½‘ç»œæœç´¢)
            search_signals = []
            if query and isinstance(intent_info, dict):
                search_queries = intent_info.get("search_queries", [query])
                is_specific = intent_info.get("is_specific_event", False)
                
                if is_specific or len(search_queries) > 0:
                    cb.phase("ä¸»åŠ¨æœç´¢", 22)
                    cb.step("thought", "TrendAgent", f"ğŸ” æ‰§è¡Œä¸»åŠ¨æœç´¢: {search_queries[:2]}")
                    
                    for q in search_queries[:2]:  # é™åˆ¶æŸ¥è¯¢æ•°
                        cb.step("tool_call", "TrendAgent", f"search_list('{q}', max_results=5)  # ä½¿ç”¨é»˜è®¤å¼•æ“")
                        try:
                            results = workflow.search_tools.search_list(q, max_results=5, enrich=True)  # ä½¿ç”¨é»˜è®¤å¼•æ“
                            for r in results:
                                search_signals.append({
                                    "title": r.get('title'),
                                    "url": r.get('url'),
                                    "source": r.get('source', 'Search'),
                                    "content": r.get('content'),
                                    "publish_time": r.get('publish_time') or datetime.now(),
                                    "sentiment_score": r.get('sentiment_score', 0),
                                    "id": r.get('id') or f"search_{hash(r.get('url') or '')}"
                                })
                            cb.step("result", "TrendAgent", f"âœ… æœç´¢ '{q[:20]}...': {len(results)} æ¡")
                        except Exception as e:
                            cb.step("error", "TrendAgent", f"âŒ æœç´¢å¤±è´¥: {str(e)[:50]}")
                    
                    cb.step("result", "TrendAgent", f"ğŸ” ä¸»åŠ¨æœç´¢å…±è·å– {len(search_signals)} æ¡ç»“æœ")
            
            # 1.4 æƒ…ç»ªåˆ†æ
            cb.phase("æƒ…ç»ªåˆ†æ", 28)
            cb.step("tool_call", "TrendAgent", "batch_update_sentiment(limit=50)")
            try:
                workflow.trend_agent.sentiment_toolkit.batch_update_sentiment(limit=50)
                cb.step("result", "TrendAgent", "âœ… BERT æƒ…ç»ªåˆ†æå®Œæˆ")
            except Exception as e:
                cb.step("error", "TrendAgent", f"âŒ æƒ…ç»ªåˆ†æå¤±è´¥: {str(e)[:50]}")
            
            # 1.5 è¯»å–æ•°æ®åº“æ–°é—»å¹¶åˆå¹¶
            db_news = workflow.db.get_daily_news(limit=50) or []
            
            # åˆå¹¶åˆ—è¡¨ (æœç´¢ç»“æœä¼˜å…ˆ)
            raw_news = search_signals + db_news if search_signals else db_news
            cb.step("thought", "TrendAgent", f"ğŸ“Š åˆå¹¶æ•°æ®: æœç´¢ {len(search_signals)} + æ•°æ®åº“ {len(db_news)} = {len(raw_news)} æ¡")
            
            if not raw_news:
                cb.phase("å®Œæˆ", 100)
                cb.step("warning", "System", "âš ï¸ æ— å¯ç”¨æ–°é—»æ•°æ®")
                self._running = False
                if run_state:
                    run_state.status = "completed"
                return
            
            # 1.6 LLM ç­›é€‰
            cb.phase("ä¿¡å·ç­›é€‰", 35)
            cb.step("thought", "TrendAgent", f"ğŸ§  ä½¿ç”¨ LLM ç­›é€‰ {len(raw_news)} æ¡æ–°é—» (Query: {query or 'Auto'})...")
            
            high_value_signals = workflow._llm_filter_signals(raw_news, 'auto', query)
            cb.step("result", "TrendAgent", f"ğŸ¯ ç­›é€‰å‡º {len(high_value_signals)} ä¸ªé«˜ä»·å€¼ä¿¡å·")
            
            for sig in high_value_signals[:5]:
                cb.step("signal", "TrendAgent", f"ğŸ“Œ {sig.get('title', 'Unknown')[:40]}...")
            
            if not high_value_signals:
                cb.phase("å®Œæˆ", 100)
                cb.step("warning", "System", "âš ï¸ æœªå‘ç°é«˜ä»·å€¼ä¿¡å·ï¼Œåˆ†æç»“æŸ")
                self._running = False
                if run_state:
                    run_state.status = "completed"
                return
            
            # ========== Step 2: Financial Analysis ==========
            cb.phase("é‡‘èåˆ†æ", 50)
            cb.step("phase", "System", f"ğŸ’¼ --- Step 2: Financial Analysis ({len(high_value_signals)} signals) ---")
            
            analyzed_signals = []
            total = len(high_value_signals)
            
            for i, signal in enumerate(high_value_signals):
                progress = 50 + int((i + 1) / total * 25)
                cb.phase(f"åˆ†æä¿¡å· {i+1}/{total}", progress)
                
                title = signal.get('title', 'Unknown')[:30]
                cb.step("thought", "FinAgent", f"ğŸ“Š åˆ†æ: {title}...")
                
                # æ„é€ è¾“å…¥
                content = signal.get("content") or ""
                if len(content) < 50 and signal.get("url"):
                    try:
                        content = workflow.trend_agent.news_toolkit.fetch_news_content(signal["url"]) or ""
                    except:
                        pass
                input_text = f"ã€{signal['title']}ã€‘\n{content[:3000]}"
                
                try:
                    # è°ƒç”¨ FinAgent
                    sig_obj = workflow.fin_agent.analyze_signal(input_text, news_id=signal.get("id"))
                    
                    if sig_obj:
                        # è¡¥å……æ¥æº
                        if not sig_obj.sources and signal.get("url"):
                            sig_obj.sources = [{
                                "title": signal["title"],
                                "url": signal["url"],
                                "source_name": signal.get("source", "Unknown")
                            }]
                        
                        sig_dict = sig_obj.dict()
                        analyzed_signals.append(sig_dict)
                        
                        # æ¨é€ä¿¡å·åˆ° Dashboard
                        cb.signal(sig_dict)
                        
                        # ISQ è¯„åˆ†
                        isq_str = f"I={sig_obj.intensity}, S={sig_obj.sentiment_score:.2f}, C={sig_obj.confidence:.2f}"
                        cb.step("signal", "FinAgent", f"ğŸ“Š ISQ: {isq_str}")
                        
                        # æ¨é€æ ‡çš„ä¿¡æ¯
                        for ticker in sig_obj.impact_tickers[:2]:
                            ticker_code = ticker.get("ticker", "")
                            ticker_name = ticker.get("name", "")
                            if ticker_code:
                                cb.step("result", "FinAgent", f"â†’ {ticker_name} ({ticker_code})")
                                
                                # å°è¯•è·å–ä»·æ ¼æ•°æ®æ¨é€å›¾è¡¨
                                try:
                                    prices = workflow.trend_agent.stock_toolkit.get_stock_price(ticker_code, days=30)
                                    if prices:
                                        chart_data = self._format_chart_data(ticker_code, ticker_name, prices)
                                        cb.chart(ticker_code, chart_data)
                                except:
                                    pass
                        
                        # ä¼ å¯¼é“¾
                        if sig_obj.transmission_chain:
                            chain = " â†’ ".join([n.node_name for n in sig_obj.transmission_chain[:3]])
                            cb.step("thought", "FinAgent", f"ğŸ”— {chain}")
                            
                            # æ¨é€ä¼ å¯¼å›¾
                            graph = self._build_graph(sig_obj)
                            cb.graph(graph)
                        
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        workflow.db.save_signal(sig_dict)
                    else:
                        cb.step("warning", "FinAgent", f"âš ï¸ æ— æ³•è§£æ: {title}")
                        
                except Exception as e:
                    cb.step("error", "FinAgent", f"âŒ åˆ†æå¤±è´¥: {str(e)[:50]}")
            
            if not analyzed_signals:
                cb.phase("å®Œæˆ", 100)
                cb.step("warning", "System", "âš ï¸ åˆ†ææœªäº§å‡ºæœ‰æ•ˆä¿¡å·")
                self._running = False
                if run_state:
                    run_state.status = "completed"
                return
            
            # æ›´æ–° run_state
            if run_state:
                run_state.signals = analyzed_signals
            
            # ========== Step 3: Report Generation ==========
            cb.phase("æŠ¥å‘Šç”Ÿæˆ", 85)
            cb.step("phase", "System", "ğŸ“ --- Step 3: Report Generation ---")
            
            cb.step("thought", "ReportAgent", "ä¿¡å·èšç±»åˆ†æ...")
            cb.step("thought", "ReportAgent", "è§„åˆ’æŠ¥å‘Šç»“æ„ (Map-Reduce)...")
            
            try:
                result = workflow.report_agent.generate_report(analyzed_signals, user_query=query)
                md_content = result.content if hasattr(result, "content") else str(result)
                
                cb.step("thought", "ReportAgent", "ç”Ÿæˆç« èŠ‚å†…å®¹...")
                cb.step("thought", "ReportAgent", "æ¸²æŸ“å›¾è¡¨...")
                
                # ä¿å­˜æŠ¥å‘Š
                from utils.md_to_html import save_report_as_html
                import os
                
                report_dir = "reports"
                os.makedirs(report_dir, exist_ok=True)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                md_filename = f"{report_dir}/daily_report_{timestamp}.md"
                
                with open(md_filename, "w", encoding="utf-8") as f:
                    f.write(md_content)
                
                html_filename = save_report_as_html(md_filename)
                
                cb.step("result", "ReportAgent", f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {html_filename or md_filename}")
                
            except Exception as e:
                cb.step("error", "ReportAgent", f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)[:50]}")
            
            # å®Œæˆ
            cb.phase("å®Œæˆ", 100)
            cb.step("system", "System", "âœ… SignalFlux åˆ†æå®Œæˆï¼")
            cb.step("result", "System", f"ğŸ“Š ä¿¡å·: {len(analyzed_signals)} | è€—æ—¶: ~{datetime.now().strftime('%H:%M:%S')}")
            
            if run_state:
                run_state.status = "completed"
                
        except Exception as e:
            cb.step("error", "System", f"âŒ å·¥ä½œæµå¤±è´¥: {str(e)}")
            if run_state:
                run_state.status = "failed"
        finally:
            self._running = False
    
    def _format_chart_data(self, ticker: str, name: str, prices: Any) -> dict:
        """æ ¼å¼åŒ–ä»·æ ¼æ•°æ®ä¸ºå›¾è¡¨æ ¼å¼"""
        price_list = []
        
        if isinstance(prices, str):
            # è§£æå­—ç¬¦ä¸²æ ¼å¼
            import re
            lines = prices.strip().split('\n')
            for line in lines:
                match = re.search(r'(\d{4}-\d{2}-\d{2}).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)', line)
                if match:
                    price_list.append({
                        "date": match.group(1),
                        "open": float(match.group(2)),
                        "high": float(match.group(3)),
                        "low": float(match.group(4)),
                        "close": float(match.group(5)),
                        "volume": 0
                    })
        elif isinstance(prices, list):
            for p in prices:
                if isinstance(p, dict):
                    price_list.append({
                        "date": str(p.get("date", "")),
                        "open": float(p.get("open", 0)),
                        "high": float(p.get("high", 0)),
                        "low": float(p.get("low", 0)),
                        "close": float(p.get("close", 0)),
                        "volume": int(p.get("volume", 0))
                    })
        
        return {
            "ticker": ticker,
            "name": name,
            "prices": price_list[-30:] if price_list else []
        }
    
    def _build_graph(self, signal) -> dict:
        """ä» InvestmentSignal æ„å»ºä¼ å¯¼å›¾"""
        nodes = []
        edges = []
        
        for i, node in enumerate(signal.transmission_chain):
            node_id = f"n{i}"
            node_type = "event" if i == 0 else "impact"
            nodes.append({
                "id": node_id,
                "label": node.node_name,
                "type": node_type,
                "impact": node.impact_type
            })
            if i > 0:
                edges.append({
                    "from": f"n{i-1}",
                    "to": node_id,
                    "label": node.impact_type
                })
        
        # æ·»åŠ æ ‡çš„
        for j, ticker in enumerate(signal.impact_tickers[:3]):
            ticker_id = f"t{j}"
            nodes.append({
                "id": ticker_id,
                "label": f"{ticker.get('name', '')} ({ticker.get('ticker', '')})",
                "type": "stock"
            })
            if nodes:
                edges.append({
                    "from": f"n{len(signal.transmission_chain)-1}" if signal.transmission_chain else "n0",
                    "to": ticker_id,
                    "label": ""
                })
        
        return {"nodes": nodes, "edges": edges}


# å…¨å±€å•ä¾‹
workflow_runner = WorkflowRunner()
